# LLM Inference Requirements - Phase 1

# Core ML frameworks
torch>=2.1.0
transformers>=4.44.0
accelerate>=0.25.0

# API framework
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
pydantic>=2.5.0

# Utilities
aiohttp>=3.9.0
python-multipart>=0.0.6

# Optional: Quantization support
# bitsandbytes>=0.41.0
# auto-gptq>=0.5.0

