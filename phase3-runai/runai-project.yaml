# Run:AI Project Configuration
# Creates a project with GPU quota allocation
#
# OPEN-SOURCE RUN:AI COMPATIBLE (v2 API)
# Apply this after installing open-source Run:AI cluster

apiVersion: run.ai/v2
kind: Project
metadata:
  name: llm-inference
spec:
  # Simplified spec for open-source version
  # The namespace will be created automatically as: runai-llm-inference
  deservedGpus: 1

