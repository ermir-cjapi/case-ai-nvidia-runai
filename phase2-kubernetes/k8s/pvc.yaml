apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: llm-model-storage
  namespace: default
spec:
  accessModes:
    - ReadWriteMany  # Multiple pods can read the same model
  resources:
    requests:
      storage: 20Gi  # Enough for Llama 3.2 3B (~8GB) with headroom
  
---
# Alternative: Using hostPath for single-node clusters (K3s, minikube)
# Uncomment if using single-node setup
# apiVersion: v1
# kind: PersistentVolume
# metadata:
#   name: llm-model-pv
# spec:
#   capacity:
#     storage: 20Gi
#   accessModes:
#     - ReadWriteMany
#   hostPath:
#     path: /data/llm-models  # Create this directory on your node
#     type: DirectoryOrCreate
#   storageClassName: standard

