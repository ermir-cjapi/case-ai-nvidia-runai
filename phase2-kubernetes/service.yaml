apiVersion: v1
kind: Service
metadata:
  name: llm-inference
  namespace: default
  labels:
    app: llm-inference
spec:
  type: NodePort  # Use NodePort for external access
  selector:
    app: llm-inference
  ports:
  - port: 8000
    targetPort: 8000
    nodePort: 30080  # Access via http://<node-ip>:30080
    protocol: TCP
    name: http

---
# Alternative: LoadBalancer service (if your cluster supports it)
# apiVersion: v1
# kind: Service
# metadata:
#   name: llm-inference-lb
#   namespace: default
# spec:
#   type: LoadBalancer
#   selector:
#     app: llm-inference
#   ports:
#   - port: 80
#     targetPort: 8000
#     protocol: TCP

